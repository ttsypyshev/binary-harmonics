import random

# исходный "битовый" текст
# (я не запаривался и сделал его не битовым, но по идее это должен быть файл в двоичном представлении)
# text = "1010111111"
text = ''.join(random.choice('01') for _ in range(1000))
print("Исходный текст:", text)

# массив с текстом и соответствующему его флагу
# (флаг используется для того, что бы пропускать при поиске уже отмеченые гормоникой биты и не создавать лишние гормоники)
text_check = [(char, False) for char in text]

# мапа гормоник, где гормоника какое-то чередование, где начиная с i с шагом step по тексту будут только одни 1
harmonics = {}  # i: step

n = len(text)
for i in range(n):
    # проходимся по всем "неотмеченым" единицам
    if (text_check[i][0] == "1" and text_check[i][1] == False):
        for step in range(1, n):
            # перебираем шаг до первой возможной гормоники
            # (что бы все биты текста, начиная с i % step с шагом step были 1)
            if all(text[j] == "1" for j in range(i % step, n, step)):
                # помечаем биты из этой гормоники как использованые
                for idx in range(i % step, n, step):
                    text_check[idx] = (text_check[idx][0], True)
                # сохраняем эту гормонику
                harmonics.setdefault(i % step, set()).add(step)
                break
        # если не нашли гормонику, то сохраняем как "единичную" гормонику
        # (ну не получается создать гормонику с этой значащей единицей, что бы попадала ещё одна 1 и не попадал 0)
        # например при text = 00000001
        else:
            text_check[i] = (text_check[i][0], True)
            harmonics.setdefault(i, set()).add(n-i)

# перепроверка на оставшиеся единицы
for char in text_check:
    if (char[0]=="1" and char[1]==False):
        print("ERROR!!!")
    
# подсчет общего количества гормоник
total_harmonics = sum(len(steps) for steps in harmonics.values())
print("Итоговые гормоники:", harmonics)
print("Общее количество гормоник:", total_harmonics)

# Будет ли эффективен этот алгоритм для сжатия рандомного набора информации на огромных масштабах?
# Можно ли использовать этот метод для приведения в набор данных из "слов" для сжатия словарными методами?
# Можно ли оптимизировать этот метод, что бы он работал на байтах, без конвертации в биты?
# Можно ли переделать этот метод, что бы он работал в небольших буфферах без использования всего битового текста?
# Есть ли зависимость количества гормоник от частоты единиц?
